{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFwpE3hWPgvU"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe0oBpPkPikC"
      },
      "source": [
        "#IMPORTING DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mekDewSkPlFS"
      },
      "source": [
        "import pandas as pd\n",
        "from pandas.api.types import is_string_dtype\n",
        "\n",
        "d=pd.read_csv('Heart.csv')\n",
        "#print(d.columns)\n",
        "#checking missing values\n",
        "#for i in d:\n",
        "  #print(d[i].unique())\n",
        "#no missing value found"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NCBX02nSXhy"
      },
      "source": [
        "#SPLIT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FviyL8A-SY7q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "f94eb09d-ad74-443f-ecbf-6177e29eecc7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = d.loc[:,d.columns!='target']\n",
        "y = d['target']\n",
        "#print(x)\n",
        "#print(y)\n",
        "#print(y.unique())\n",
        "train_val_x, test_x, train_val_y, test_y = train_test_split(x,y,test_size=0.2,random_state=1)\n",
        "train_x, val_x, train_y, val_y = train_test_split(train_val_x,train_val_y,test_size=0.08,random_state=1)\n",
        "#print(len(train_x),len(val_x),len(test_x))\n",
        "#print(len(train_y),len(val_y),len(test_y))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'target'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-48db4b164ec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#print(y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'target'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh3A7itpXeey"
      },
      "source": [
        "#Continuous Feature Handling(Binarization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yzcWf6dXnhy"
      },
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "con_col=['age','trestbps','chol','thalach','oldpeak']\n",
        "b_train_x = pd.DataFrame()\n",
        "b_val_x= pd.DataFrame()\n",
        "b_test_x = pd.DataFrame()\n",
        "b_train_val_x= pd.DataFrame()\n",
        "\n",
        "train_x.reset_index(drop=True, inplace=True)\n",
        "val_x.reset_index(drop=True, inplace=True)\n",
        "test_x.reset_index(drop=True, inplace=True)\n",
        "train_val_x.reset_index(drop=True, inplace=True)\n",
        "\n",
        "for i in train_x.columns:\n",
        "  if i in con_col:\n",
        "    bin=Binarizer(threshold=train_x[i].mean())\n",
        "    b_train_x[i]=bin.transform(train_x[[i]]).flatten()\n",
        "    b_val_x[i]=bin.transform(val_x[[i]]).flatten()\n",
        "    b_train_val_x[i]=bin.transform(train_val_x[[i]]).flatten()\n",
        "    b_test_x[i]=bin.transform(test_x[[i]]).flatten()\n",
        "  else:\n",
        "    b_train_x[i] = train_x[i].copy()\n",
        "    b_train_val_x[i] = train_val_x[i].copy()\n",
        "    b_val_x[i] = val_x[i].copy()\n",
        "    b_test_x[i] = test_x[i].copy()\n",
        "#print(b_train_x)\n",
        "#print(b_val_x)\n",
        "#print(b_test_x)\n",
        "#for i in b_train_x:\n",
        "  #print(b_train_x[i].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg3Z46ZIaNxz"
      },
      "source": [
        "#Continuous Feature Handling(Quantization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wyi-ZTdTaYuz"
      },
      "source": [
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "q_train_x = pd.DataFrame()\n",
        "q_val_x= pd.DataFrame()\n",
        "q_test_x = pd.DataFrame()\n",
        "q_train_val_x= pd.DataFrame()\n",
        "\n",
        "\n",
        "for col in train_x.columns:\n",
        "  if col in con_col:\n",
        "    bin = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
        "    bin.fit(train_x[[col]])\n",
        "    q_train_x[col] = bin.transform(train_x[[col]]).flatten()\n",
        "    q_train_val_x[col] = bin.transform(train_val_x[[col]]).flatten()\n",
        "    q_val_x[col] = bin.transform(val_x[[col]]).flatten()\n",
        "    q_test_x[col] = bin.transform(test_x[[col]]).flatten()\n",
        "  else:\n",
        "    q_train_x[col] = train_x[col].copy()\n",
        "    q_train_val_x[col] = train_val_x[col].copy()\n",
        "    q_val_x[col] = val_x[col].copy()\n",
        "    q_test_x[col] = test_x[col].copy()\n",
        "\n",
        "#print(q_train_x)\n",
        "#print(q_val_x)\n",
        "#print(q_test_x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMoKSMl7jw9Q"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Random Forest Classifier Predicting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCOVA07tj00w"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "n_estimatorslist=[10,20,40,60,80,100,120,140,160,180,200]\n",
        "criterion_list=['gini','entropy']\n",
        "\n",
        "#for binarization part\n",
        "best_acc = -np.inf\n",
        "\n",
        "for n in n_estimatorslist:\n",
        "  for c in criterion_list:\n",
        "    rfmodel=RandomForestClassifier(n_estimators=n,criterion=c,random_state=1)\n",
        "    rfmodel.fit(b_train_x,train_y)\n",
        "    predictions=rfmodel.predict(b_val_x)\n",
        "    acc=accuracy_score(val_y, predictions)\n",
        "    if acc > best_acc:\n",
        "      best_acc=acc\n",
        "      best_n_estimators=n\n",
        "      best_criterion=c\n",
        "#print(best_acc,best_n_estimators,best_criterion)\n",
        "\n",
        "rfmodel=RandomForestClassifier(n_estimators=best_n_estimators,criterion=best_criterion,random_state=1)\n",
        "rfmodel.fit(b_train_val_x,train_val_y)\n",
        "predictions=rfmodel.predict(b_test_x)\n",
        "acc=accuracy_score(test_y, predictions)\n",
        "print(f'RandomForestBinarization Accuracy: {acc}')\n",
        "\n",
        "#for quantization part\n",
        "best_acc = -np.inf\n",
        "for n in n_estimatorslist:\n",
        "  for c in criterion_list:\n",
        "    rfmodel=RandomForestClassifier(n_estimators=n,criterion=c,random_state=1)\n",
        "    rfmodel.fit(q_train_x,train_y)\n",
        "    predictions=rfmodel.predict(q_val_x)\n",
        "    acc=accuracy_score(val_y, predictions)\n",
        "    if acc > best_acc:\n",
        "      best_acc=acc\n",
        "      best_n_estimators=n\n",
        "      best_criterion=c\n",
        "#print(best_acc,best_n_estimators,best_criterion)\n",
        "rfmodel=RandomForestClassifier(n_estimators=best_n_estimators,criterion=best_criterion,random_state=1)\n",
        "rfmodel.fit(q_train_val_x,train_val_y)\n",
        "predictions=rfmodel.predict(q_test_x)\n",
        "acc=accuracy_score(test_y, predictions)\n",
        "print(f'RandomForestQuantization Accuracy: {acc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9Rz0_YTB1y1"
      },
      "source": [
        "# Logistic Regression Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueS_mZvNCck5"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "c_list=[0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "maxiter_list= list(range(100,800,100))\n",
        "\n",
        "#for binarization part\n",
        "best_acc = -np.inf\n",
        "\n",
        "for c in c_list:\n",
        "  for iter in maxiter_list:\n",
        "    lgmodel=LogisticRegression(C=c,max_iter=iter,random_state=1)\n",
        "    lgmodel.fit(b_train_x,train_y)\n",
        "    predictions=lgmodel.predict(b_val_x)\n",
        "    acc=accuracy_score(val_y, predictions)\n",
        "    if acc > best_acc:\n",
        "      best_acc=acc\n",
        "      best_c=c\n",
        "      best_iter=iter\n",
        "\n",
        "lgmodel=LogisticRegression(C=best_c,max_iter=best_iter,random_state=1)\n",
        "lgmodel.fit(b_train_val_x,train_val_y)\n",
        "predictions=lgmodel.predict(b_test_x)\n",
        "acc=accuracy_score(test_y, predictions)\n",
        "print(f'LogisticRegressionBinarization Accuracy: {acc}')\n",
        "\n",
        "\n",
        "\n",
        "#for quantization\n",
        "best_acc = -np.inf\n",
        "\n",
        "for c in c_list:\n",
        "  for iter in maxiter_list:\n",
        "    lgmodel=LogisticRegression(C=c,max_iter=iter,random_state=1)\n",
        "    lgmodel.fit(q_train_x,train_y)\n",
        "    predictions=lgmodel.predict(q_val_x)\n",
        "    acc=accuracy_score(val_y, predictions)\n",
        "    if acc > best_acc:\n",
        "      best_acc=acc\n",
        "      best_c=c\n",
        "      best_iter=iter\n",
        "\n",
        "lgmodel=LogisticRegression(C=best_c,max_iter=best_iter,random_state=1)\n",
        "lgmodel.fit(q_train_val_x,train_val_y)\n",
        "predictions=lgmodel.predict(q_test_x)\n",
        "acc=accuracy_score(test_y, predictions)\n",
        "print(f'LogisticRegressionQuantization Accuracy: {acc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCNiHpFmiiMf"
      },
      "source": [
        "#Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_SWXW2SioAM"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "alpha_list=[1.0,2.0,4.0,6.0,8.0,10.0,1.2,1.4,1.6,1.8]\n",
        "\n",
        "#for binarization part\n",
        "best_acc = -np.inf\n",
        "\n",
        "for a in alpha_list:\n",
        "  mnModel=MultinomialNB(alpha=a)\n",
        "  mnModel.fit(b_train_x,train_y)\n",
        "  predictions=mnModel.predict(b_val_x)\n",
        "  acc=accuracy_score(val_y, predictions)\n",
        "  if acc > best_acc:\n",
        "    best_acc=acc\n",
        "    best_alpha=a\n",
        "#print(best_acc,best_alpha)\n",
        "\n",
        "mnModel=MultinomialNB(alpha=best_alpha)\n",
        "mnModel.fit(b_train_val_x,train_val_y)\n",
        "predictions=mnModel.predict(b_test_x)\n",
        "acc=accuracy_score(test_y, predictions)\n",
        "print(f'NaiveBayesBinarization Accuracy: {acc}')\n",
        "\n",
        "#for quantization part\n",
        "best_acc = -np.inf\n",
        "\n",
        "for a in alpha_list:\n",
        "  mnModel=MultinomialNB(alpha=a)\n",
        "  mnModel.fit(q_train_x,train_y)\n",
        "  predictions=mnModel.predict(q_val_x)\n",
        "  acc=accuracy_score(val_y, predictions)\n",
        "  if acc > best_acc:\n",
        "    best_acc=acc\n",
        "    best_alpha=a\n",
        "#print(best_acc,best_alpha)\n",
        "mnModel=MultinomialNB(alpha=best_alpha)\n",
        "mnModel.fit(q_train_val_x,train_val_y)\n",
        "predictions=mnModel.predict(q_test_x)\n",
        "acc=accuracy_score(test_y, predictions)\n",
        "print(f'NaiveBayesQuantization Accuracy: {acc}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gCckCsQdNz2"
      },
      "source": [
        "#SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1mR_dFidPFX"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "c_list=[0.1,1.0,2.0,4.0,6, 10, 100]\n",
        "gamma_list=[0.01,0.001,0.0001,0.1,0.00001,1]\n",
        "\n",
        "\n",
        "#for binarization part\n",
        "best_acc = -np.inf\n",
        "\n",
        "for c in c_list:\n",
        "  for gamma in gamma_list:\n",
        "    svm = SVC(C=c,gamma = gamma,random_state=1)\n",
        "    svm.fit(b_train_x,train_y)\n",
        "    predictions=svm.predict(b_val_x)\n",
        "    acc=accuracy_score(val_y, predictions)\n",
        "    if acc > best_acc:\n",
        "      best_acc=acc\n",
        "      best_c=c\n",
        "      best_gamma=gamma\n",
        "\n",
        "#print(\"Binarization SVM best acc = \", best_acc)\n",
        "#print(\"Binarization SVM best c = \", best_c)\n",
        "#print(\"Binarization SVM best acc = \", best_gamma)\n",
        "\n",
        "svm = SVC(C=best_c,gamma = best_gamma,random_state=1)\n",
        "svm.fit(b_train_val_x,train_val_y)\n",
        "predictions=svm.predict(b_test_x)\n",
        "acc=accuracy_score(test_y, predictions)\n",
        "print(f'SVMBinarization Accuracy: {acc}')\n",
        "\n",
        "#for quantization part\n",
        "best_acc = -np.inf\n",
        "for c in c_list:\n",
        "  for gamma in gamma_list:\n",
        "    svm=SVC(C=c,gamma = gamma,random_state=1)\n",
        "    svm.fit(q_train_x,train_y)\n",
        "    predictions=svm.predict(q_val_x)\n",
        "    acc=accuracy_score(val_y, predictions)\n",
        "    if acc > best_acc:\n",
        "      best_acc=acc\n",
        "      best_c=c\n",
        "      best_gamma=gamma\n",
        "\n",
        "#print(\"Quant SVM best acc = \", best_acc)\n",
        "#print(\"Quant SVM best c = \", best_c)\n",
        "#print(\"Quant SVM best acc = \", best_gamma)\n",
        "\n",
        "#print(best_acc,best_n_estimators,best_criterion)\n",
        "svm = SVC(C=best_c,gamma = best_gamma,random_state=1)\n",
        "svm.fit(q_train_val_x,train_val_y)\n",
        "predictions=svm.predict(q_test_x)\n",
        "acc=accuracy_score(test_y, predictions)\n",
        "print(f'SVMQuantization Accuracy: {acc}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPwep_g8n7TE"
      },
      "source": [
        "#Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDYaI2wGn-ON"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "min_samples_split_list=range(2, 10)\n",
        "max_features_list = [1,2,4,6,8,10,'auto','sqrt','log2']\n",
        "criterion_list=[\"gini\", \"entropy\"]\n",
        "\n",
        "\n",
        "#for binarization part\n",
        "best_acc = -np.inf\n",
        "\n",
        "for min_samples in min_samples_split_list:\n",
        "  for max_features in max_features_list:\n",
        "    for criterion in criterion_list:\n",
        "      dt = DecisionTreeClassifier(criterion = criterion,min_samples_split = min_samples, max_features = max_features, random_state=1)\n",
        "      dt.fit(b_train_x,train_y)\n",
        "      predictions=dt.predict(b_val_x)\n",
        "      acc=accuracy_score(val_y, predictions)\n",
        "      if acc > best_acc:\n",
        "        best_acc=acc\n",
        "        best_criterion = criterion\n",
        "        best_min_samples=min_samples\n",
        "        best_max_features=max_features\n",
        "\n",
        "#print(\"Binarization dt best acc = \", best_acc)\n",
        "#print(\"Binarization dt best criterion = \", best_criterion)\n",
        "#print(\"Binarization dt best min_samples = \", best_min_samples)\n",
        "#print(\"Binarization dt best min_samples = \", best_max_features)\n",
        "\n",
        "dt = DecisionTreeClassifier(criterion = criterion,min_samples_split = min_samples, max_features = max_features, random_state=1)\n",
        "dt.fit(b_train_val_x,train_val_y)\n",
        "predictions=dt.predict(b_test_x)\n",
        "acc=accuracy_score(test_y, predictions)\n",
        "print(f'DecisionTreeBinarization Accuracy: {acc}')\n",
        "\n",
        "#for quantization part\n",
        "best_acc = -np.inf\n",
        "\n",
        "for min_samples in min_samples_split_list:\n",
        "  for max_features in max_features_list:\n",
        "    for criterion in criterion_list:\n",
        "      dt=DecisionTreeClassifier(criterion = criterion,min_samples_split = min_samples, max_features = max_features, random_state=1)\n",
        "      dt.fit(q_train_x,train_y)\n",
        "      predictions=dt.predict(q_val_x)\n",
        "      acc=accuracy_score(val_y, predictions)\n",
        "      if acc > best_acc:\n",
        "        best_acc=acc\n",
        "        best_criterion = criterion\n",
        "        best_min_samples=min_samples\n",
        "      best_max_features=max_features\n",
        "\n",
        "#print(\"Quant dt best acc = \", best_acc)\n",
        "#print(\"Quant dt best criterion = \", best_criterion)\n",
        "#print(\"Quant dt best min_samples = \", best_min_samples)\n",
        "#print(\"Quant dt best min_samples = \", best_max_features)\n",
        "\n",
        "#print(best_acc,best_n_estimators,best_criterion)\n",
        "dt = DecisionTreeClassifier(criterion = criterion,min_samples_split = min_samples, max_features = max_features, random_state=1)\n",
        "dt.fit(q_train_val_x,train_val_y)\n",
        "predictions=dt.predict(q_test_x)\n",
        "acc=accuracy_score(test_y, predictions)\n",
        "print(f'DecisionTreeQuantization Accuracy: {acc}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}